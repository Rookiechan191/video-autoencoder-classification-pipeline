# WeldNet: Real-Time Unsupervised Welding Defect Classification

A production-ready PyTorch pipeline for classifying 12 robotic welding conditions directly from RGB video using the Intel Robotic Welding Dataset (2024).

WeldNet combines unsupervised latent learning + lightweight supervised classification, inspired by modern SSL representation learning (e.g., arXiv:2409.02290) but fully optimized for industrial robotic welding.

---

## Highlights

- **No temporal or frame-level labels required**
-  **R3D-18** (Kinetics-400 pretrained) + Autoencoder bottleneck (64-d)
-  **Memory-efficient training** with video chunking
-  **Complete training â†’ validation â†’ evaluation pipeline** (5 commands)

---

## Project Structure

```
intel_robotic_welding_dataset/
â”œâ”€â”€ raid/
â”‚   â””â”€â”€ intel_robotic_welding_dataset/
â”‚       â”œâ”€â”€ manifest.csv
â”‚       â”œâ”€â”€ good_weld_.../
â”‚       â”œâ”€â”€ lack_of_fusion_.../
â”‚       â””â”€â”€ ...
â”œâ”€â”€ checkpoints/                  # Autoencoder weights
â”‚   â”œâ”€â”€ latest_checkpoint.pt
â”‚   â””â”€â”€ best_model.pt
â”œâ”€â”€ checkpoints_val/              # Classifier weights
â”‚   â”œâ”€â”€ val_latest_checkpoint.pt
â”‚   â””â”€â”€ val_best_model.pt
â”œâ”€â”€ train_welding_model.py        # Stage 1: Unsupervised AE training
â”œâ”€â”€ val_welding_model.py          # Stage 2: Classifier training
â”œâ”€â”€ test_video.py                 # TEST split evaluation â†’ CSV + confusion matrix
â”œâ”€â”€ single_video.py               # Real-time inference on any .avi file
â”œâ”€â”€ check_file.py                 # Inspect .pt checkpoints
â””â”€â”€ README.md
```

---

## Quick Start (5 Commands)

### 1. Train the Autoencoder (Unsupervised Stage)

```bash
python train_welding_model.py
```

### 2. Train the Classifier on Frozen Latents

```bash
python val_welding_model.py
```

### 3. Evaluate on the Official TEST Split

Generates:
- Confusion matrix
- Per-class accuracy
- Predictions CSV

```bash
python test_video.py
```

### 4. Real-Time Inference on Any Video

Edit `video_path` inside the script:

```bash
python single_video.py
```

### 5. Inspect a Checkpoint

```bash
python check_file.py
```

---

## Model Pipeline Overview

```
Video (.avi)
    â†“
(Sliding window: 16 frames, stride 8â€“128)
    â†“
Clip batch
    â†“
R3D-18 (Kinetics-400 pretrained)
    â†“
â†’ 512-d features
    â†“
Truncate to 400 dims
    â†“
Autoencoder (400 â†’ 64 â†’ 400)
    â†“
â†’ mean-pooled 64-d latent
    â†“
2-layer MLP classifier
    â†“
12-class prediction
```

---

## ğŸ› ï¸ Technical Details

### Backbone
- `torchvision.models.video.r3d_18(weights="KINETICS400_V1")`

### Autoencoder
- **Architecture:** 400 â†’ 256 â†’ 64 â†’ 256 â†’ 400
- **Loss:** SmoothL1 + latent L2 (1e-4)

### Classifier
- **MLP:** 64 â†’ 128 â†’ 12
- **Loss:** Cross-Entropy
- **Optimizer:** Adam

### Environment
- PyTorch 2.3+
- CUDA 11.8 / 12.x
- OpenCV 4.8+

---

## References

1. Intel Corporation, *Intel Robotic Welding Dataset*, 2024.  
   [HuggingFace Dataset](https://huggingface.co/datasets/IntelLabs/Intel_Robotic_Welding_Multimodal_Dataset)

2. W. Kay et al., "The Kinetics Human Action Video Dataset," arXiv:1705.06950 (2017).

3. K. Hara et al., "Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs?," CVPR 2018.

4. T. Chen et al., "Self-Supervised Learning of Visual Representations from Uncurated Data," arXiv:2409.02290 (2024).

---

## License

This project uses the Intel Robotic Welding Dataset. Please refer to the dataset's license for usage terms.

---
